{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ejerciciopropuesto_ModuloTextMining.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ruben9324/curso-series-temporales/blob/master/Ejerciciopropuesto_ModuloTextMining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pOub-BB9KWh5"
      },
      "outputs": [],
      "source": [
        "# Descarga de archivos de ProfNER\n",
        "!wget https://zenodo.org/record/4563995/files/profner.zip?download=1\n",
        "# Si el unzip no funciona, revisar cual es el nombre de descarga del archivo\n",
        "!unzip  profner.zip?download=1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Funciones de carga y preparación de datos"
      ],
      "metadata": {
        "id": "orbd2vE2XHWN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "import pandas as pd\n",
        "def get_tweet_content(list_paths):\n",
        "  \"\"\"\n",
        "    Función para guardar en un diccionario el contenido de archivos txt \n",
        "    que se introduce en su entrada. \n",
        "    Devuelve un diccionario en el que las claves son el id del tweet, y\n",
        "    el valor el texto del tweet.\n",
        "  \"\"\"\n",
        "  output_dict = dict()\n",
        "  for i in list_paths:\n",
        "    tweet_id = i.split(\"/\")[-1].split(\".txt\")[0]\n",
        "    with open(i) as f:\n",
        "      output_dict[int(tweet_id)] = f.read()\n",
        "  \n",
        "  return output_dict\n",
        "\n",
        "def get_profner_data(profner_path_data):\n",
        "    # Obtenemos el path a los txt de los tweets.\n",
        "    path_to_txt = profner_path_data+\"subtask-1/train-valid-txt-files/\"\n",
        "    tweets_train_files = [path_to_txt+\"train/\"+i for i in os.listdir(path_to_txt+\"train/\")]\n",
        "    tweets_valid_files = [path_to_txt+\"valid/\"+i for i in os.listdir(path_to_txt+\"valid/\")]\n",
        "    # Obtenemos diccionarios en los que el key es el tweet_id y el value el texto del tweet.\n",
        "    train_txt_content = get_tweet_content(tweets_train_files)\n",
        "    valid_txt_content = get_tweet_content(tweets_valid_files)\n",
        "\n",
        "    # Cargamos dos dataframes con los tweet_id y la categoría de los tweets\n",
        "    path_to_labeled = profner_path_data+\"subtask-1/\"\n",
        "    train_tweets = pd.read_csv(path_to_labeled+\"train.tsv\",sep=\"\\t\")\n",
        "    valid_tweets = pd.read_csv(path_to_labeled+\"valid.tsv\",sep=\"\\t\")\n",
        "\n",
        "    # Introducimos a los df el campo de texto mapeando los diccionarios con tweet_id\n",
        "    train_tweets[\"tweet_text\"] = train_tweets['tweet_id'].map(train_txt_content)\n",
        "    train_tweets[\"set\"] = \"train\"\n",
        "    valid_tweets[\"tweet_text\"] = valid_tweets['tweet_id'].map(valid_txt_content)\n",
        "    valid_tweets[\"set\"] = \"valid\"\n",
        "\n",
        "    # Concatenamos el resultado\n",
        "    output_df = pd.concat([train_tweets,valid_tweets],axis=0)\n",
        "    # Eliminamos retorno de carro\n",
        "    output_df[\"tweet_text\"] = output_df.tweet_text.apply(lambda x: x.replace('\\n', ' '))\n",
        "    return output_df[[\"tweet_id\",\"tweet_text\",\"label\",\"set\"]].reset_index(drop=True)"
      ],
      "metadata": {
        "id": "3heKghCvKivQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "iICP2JDiW_J1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejercicio\n"
      ],
      "metadata": {
        "id": "OeczIz9uKyBV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este ejercicio se trabajará con un conjunto de datos reales publicados para la shared-task [ProfNER](https://temu.bsc.es/smm4h-spanish/), celebrada en el año 2021. Específicamente, se utilizarán los datos textuales de la subtarea 1, centrada en la clasificación de textos. Este conjunto de datos son tweets en español que tienen asignada una etiqueta numérica, que representa la presencia (valor 1) o no (valor 0) de menciones de profesiones en el tweet. Por si fuera de tu interés, el proceso de obtención, selección y anotación de datos está descrita en [este enlace.](https://temu.bsc.es/smm4h-spanish/?p=4003).\n",
        "\n",
        "Para el ejercicio debéis entrenar diferentes modelos de clasificación que permitan clasificar correctamente los tweets. Para ello será necesario crear y utilizar funciones de preprocesado de datos similares a las vistas en clase, aplicar estrategias de vectorización de trextos como TF-IDF o embeddings, y entrenar/evaluar modelos de clasificación. Para que os sirva de orientación, los criterios de evaluación del ejercicio serán los siguientes:\n",
        "\n",
        "-\t**Análisis exploratorio, pre-procesado y normalización de los datos (30%)**:\n",
        "        -\tEl ejercicio deberá contener un análisis exploratorio de los datos como número de documentos, gráficas de distribución de longitudes y/o wordclouds, entre otros análisis que se os pudieran ocurrir. Vuestros ejercicios deberán incorporar al menos los análisis exploratorios vistos en clase.\n",
        "\n",
        "    -\tTambién tendréis que tener funciones para normalizar textos que permitan eliminar palabras vacías, quitar símbolos de puntuación y lematizar o hacer stemming.  \n",
        "\n",
        "-\t**Vectorización de textos (40%)**\n",
        "\n",
        "    En clase hemos visto diferentes estrategias de vectorización como TF-IDF y Word Embeddings. También hemos visto como incorporar características adicionales utilizando el sentimiento de los documentos. Para este ejercicio sois libres de utilizar la estrategia de vectorización que queráis, pero:\n",
        "  -\tSi decidís utilizar TF-IDF será necesarios que incorporéis a modelo características adicionales de sentimiento utilizando recursos adicionales (como por ejemplo la librería TextBlob). \n",
        "  -\tSi optáis por representar el texto mediante embeddings, dado que en clase no se profundizado sobre el tema no será necesario incorporar esas características adicionales. Si decidís esta segunda opción, podéis utilizar los embeddings en español que vimos en clase\n",
        "\n",
        "-\t**Entrenamiento y validación del sistema (30%)**\n",
        "  -\tEn el proceso de entrenamiento del modelo tendréis que testear al menos 3 modelos de clasificación. El procedimiento debe ser similar al visto en clase, en el que primero estimábamos el rendimiento de varios algoritmos de forma general, para posteriormente seleccionar el mejor para ajustar los hiperparámetros.\n"
      ],
      "metadata": {
        "id": "I9EFBbmM5w90"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Imports\n"
      ],
      "metadata": {
        "id": "u5dR3XnT7Wl1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fVOCm6Kw7WCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Obtención del corpus\n",
        "Para la obtención de los datos teneis disponible la función `get_profner_data()`. Esta función prepara los datos del ejercicio en formato Pandas dataframe para que podais realizarlo."
      ],
      "metadata": {
        "id": "WbiU7iHSKd-9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "profner_path = \"./profner/\"\n",
        "datos_ejercicio = get_profner_data(profner_path)"
      ],
      "metadata": {
        "id": "UrkhXWHjK7SQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datos_ejercicio.head(4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "T3OwCqvBKexv",
        "outputId": "0ea32d70-f172-4975-da47-64e4173ef8cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              tweet_id                                         tweet_text  \\\n",
              "0  1256007275807997953  CHINA: libera una pandemia EE.UU: libera OVNIS...   \n",
              "1  1257909427677601792  San Francisco (EEUU) hace 100 años tras vivir ...   \n",
              "2  1281580572415066112  Porfi poneos la mascarilla o tendremos 28 nuev...   \n",
              "3  1271348112733470720  El nuevo „covid normas y reglas recibimiento“ ...   \n",
              "\n",
              "   label    set  \n",
              "0      0  train  \n",
              "1      0  train  \n",
              "2      0  train  \n",
              "3      0  train  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-081b5187-9f9c-4beb-a435-bf13ceaeab44\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>tweet_text</th>\n",
              "      <th>label</th>\n",
              "      <th>set</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1256007275807997953</td>\n",
              "      <td>CHINA: libera una pandemia EE.UU: libera OVNIS...</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1257909427677601792</td>\n",
              "      <td>San Francisco (EEUU) hace 100 años tras vivir ...</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1281580572415066112</td>\n",
              "      <td>Porfi poneos la mascarilla o tendremos 28 nuev...</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1271348112733470720</td>\n",
              "      <td>El nuevo „covid normas y reglas recibimiento“ ...</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-081b5187-9f9c-4beb-a435-bf13ceaeab44')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-081b5187-9f9c-4beb-a435-bf13ceaeab44 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-081b5187-9f9c-4beb-a435-bf13ceaeab44');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Análisis exploratorio"
      ],
      "metadata": {
        "id": "jJoVvfp77ZeF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Ale01HXiOwir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Preprocesado y Normalización"
      ],
      "metadata": {
        "id": "9wseifFy7b4-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "aac98seT7cBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Vectorización"
      ],
      "metadata": {
        "id": "5vJkVg9X7cOx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3TG0_Tea7cVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Entrenamiento y evaluación de modelos\n"
      ],
      "metadata": {
        "id": "Y1EtZHFx7ij9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "lKr2GUiC7iqS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}